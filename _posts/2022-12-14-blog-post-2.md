---
title: 'Intro to Database System : Join'
date: 2022-12-14
permalink: /posts/2022/12/15445-11
tags:
  - computer science
  - database
---
## Content

1. Joins

2. Nested Loop Join

3. Sort Merge Join

4. Hash Join

## Joins

### Why we need Joins

为了减少数据冗余，我们会对关系做规范化，在查询的时候，有时候我们需要整个元组，这时候我们就需要在不丢失信息的情况下重建整个元组，这时候我们就需要 join 操作。

为了简化讨论，我们的关注点是 binary joins(multi-way join mostly appears in research) using equijoin(use equal predicate to filter) algorithms，这类方法讨论起来比较简便，且经过不大的改动可以推广到其他 join 算法。

通常来说，我们把 join 算子左侧的表称为 outer table，右侧的表称为 inner table. 在 query plan 中一般把小的表作为 outer table（optimzier 会自己搞清楚怎么选择），这么做的好处在之后关于 join algorithm 的讨论中会有体现。

### Join Operators

对于一个 join 算子，我们需要关心的设计主要有两点:

- Output：join 算子要给 query plan tree 的 parent operator 传递什么形式的输出，这里有两种策略可以选择(early materialization 选择传递整个元组，late materialization 选择传递 record id)

- Cost Analysis Criteria: 我们选择什么标准来评估一个 join 算子。

### Operator Output

join operator 把 $r \in R, s \in S$ 两个元组拼接起来形成一个新的元组，具体的输出形式和 processing model，storage model 和 query requirement 有关。

Early Materialization: 把匹配的 outer tuple 和 inner tuple 的值拷贝到输出中，这么做的好处是之后不需要再回溯到 base table，坏处是可能拷贝元组的开销比较大。

Late Materialization: 只拷贝匹配的元组的 join keys 和 record id，这种方式对于列存储数据库来说是很好的，因为刚好和列存储模型不携带不必要的信息相符合。

### Cost Analysis Criteria

我们假设: 表 R 中有 M 个 page，m 个元组，表 S 中有 N 个 page，n 个元组。

使用 # IO to compute join 作为 Cost Metric. 这种评估方式忽略了相对较小的和无法得知的因素，是一个简化但是效果尚可的指标。

下面我们将讨论几种 join algorithm，并使用该 metric 来评估这些方法。

## Nested Loop Join

### Stupid Nested Loop Join

最朴素的暴力做法，直接两重循环匹配:

```java
for (tuple r : R){ // outer
  for (tuple s : S) { // inner
        emit, if r and s match
  }
}
```

假设 R 中有 m 个元组，大小有 M 个 page，S 中有 n 个元组，大小有 N 个 page，那么朴素嵌套循环连接算法的代价是: M + m * N. Stupid Nested Loop Join 之所以效率很低的原因是对于 outer table 中的每个元组，都需要扫描一次 inner table.

### Block Nested Loop Join

```java
for (Br : R){
  for (Bs : S) {
    for (tuple r : Br){
      for (tuple s : Bs) {
        emit, if r and s match
      }
    }
  }
}
```
对 R 和 S 做了分块，这样对于每个 block 只需要扫描 S 一次，相较于原来对于每个 tuple 需要扫描 S 一次提升了效率，代价是 M + M * N.

如果我们考虑 buffer，则可以进一步提升效率：

```java
foreach B-2 pages Pr in R {
  foreach Ps in S {
    foreach tuple r in Pr {
      foreach tuple s in Ps {
        emit, if r and s match
      }
    }
  }
}
```

考虑了缓冲的代价是: $M + \lceil\frac{M}{B-2} \times N \rceil$

尽管做了一些优化，这种基础的嵌套循环连接算法当表比较大的时候仍然无法让人接受，这类方法代价大的原因是每次都要顺序地扫描 inner table 来做匹配。考虑到这，如果我们已经有一个索引，就可以通过扫描索引来避免进行顺序扫描，进一步降低代价。

### Index Nested Loop Join

```java
for (tuple r : R) {
  for (tuple s : Index(ri = sj)) {
    emit, if r and s match
  }
}
```

假设扫描索引的代价是某个常数 C，那么索引嵌套循环连接算法的代价是 M + m * C

### Nested Loop Join Summary

一些优化的小手段:

- 把小的表（以 page 数量衡量）作为 outer table
- 尽可能缓存 outer table
- 如果有索引扫描 inner table 可以用索引

algorithms:

- Simple
- Block
- Index

## Sort Merge

分为两个阶段：

Phase #1: Sort
- 把 outer table 和 inner table 排序，如果内存放不下可以用 external merge sort

Phase #2: Merge
- 用两个游标分别同时扫描 outer table 和 inner table，返回那些匹配的元组。
- 匹配失败可能需要回溯。

![](https://github.com/SUNLIFAN/images/blob/main/post/db1101.png?raw=true)

Sort Merge Join 的开销包括两个部分: Sort 和 Merge.

$SortCost(R) = 2\times M \times (1 + \lceil log_{B-1}(\lceil M/B \rceil) \rceil)$

$SortCost(S) = 2\times N \times (1 + \lceil log_{B-1}(\lceil N/B \rceil) \rceil)$

$MergeCost = M + N$

$TotalCost = SortCost(R) + SortCost(S) + MergeCost$

### When is Sort-Merge Join Useful?

- 待连接的两个表已经按 join key 排好序
- 输出结果需要排序
- 待连接的两个表的排序可以通过显式的排序算子完成，也可以通过 join key 上的 index.

## Hash Join

对于我们讨论的 equi join，如果两个元组 $r\in R,s \in S$ 满足 join condition，这意味着它们再 join key 上的值相等，如果这个值被映射到第 i 个 partition，（我们把 R 中映射到 partition i 的部分叫做 $R_i$，S 中映射到 partition i 的部分叫做 $S_i$），那么匹配的元组 r 和 s 一定会分别被映射到 $R_i$ 和 $S_i$.

因此 $R_i$ 中的元组只需要和 $S_i$ 中的元组进行匹配。

### Basic Hash Join Algorithm

整个 join algorithm 过程分为两个阶段:

Phase #1: Build

- 扫描 outer table，并使用散列函数 $h_1$ 再 join attribute 上建立散列表
- 在实际应用中大多用 linear probe

Phase #2: Probe

- 扫描 inner table，用 $h_1$ 跳转到对应的散列表中的位置进行匹配。

![](https://github.com/SUNLIFAN/images/blob/main/post/db1102.png?raw=true)

### Hash Table Content

Key: join attribute，由于我们需要进行 join attribute 上的匹配，而不同的 join attribute 也可能被 hash 到同一个 hash value，因此我们需要保留原本的 join attribute

Value: 根据具体实现而定，首先需要考虑 query plan tree 上的 parent node 需要什么样的输入，有 early materialization 和 late materialization 两种策略。

### Cost Analysis

使用 basic hash join algorithm，我们可以 hash 多大的表? 假设有 B 个 buffer page 位置，我们使用一个给输入，B-1 个 spill partition，我们的表不应该超过 B 个 block 大小。

$Cost = B\times (B-1)$

### Optimization: Probe Filter

在 build 阶段建立一个 bloom filter 数据结构，这个数据结构来指示某个 key 在 hash table 中可能不存在，在 probe 之前需要先经过 bloom filter 检查，这样可以减少不必要的 probe. 这个检查的过程的开销是很小的，因为 bloom filter 足以放在 CPU 的 cache 上面。

> 来自 https://hur.st/bloomfilter/ 的解释
> Bloom filters are space-efficient probablistic data structures used to test whether an element is a member of a set.
> They're surprisingly simple: take an array of m bits, and for up to n different elements, either test or set k bits using positions chosen using hash functions. If all bits are set, the element probably already exists, with a false positive rate of p; if any of the bits are not set, the element certainly does not exist.

简单来说，以 ADT 的视角看的话，bloom filter 是用来检测某个个元素是否是一个集合的成员，支持两个操作: Insert(x) 和 LookUp(x).

bloom filter 内含有一个 bit vector

Insert(x): 通过 k 个 hash function 来把某些 bits 设为 1

LookUp(x): 使用和 insert 相同的 k 个 hash function 来找到某些 bits，查看是否为 1，如果为 1 的话那么说明 x 可能存在。

bloom filter 只会有 false positive 不会有 false negative，这也就意味着如果它指示一个元素不存在，那么一定不存在，这使得我们的 hash join algorithm 保持了正确性。

![](https://github.com/SUNLIFAN/images/blob/main/post/db1103.png?raw=true)

### Partitioned Hash Join

如果我们没有足够的内存来容得下这个 hash table 怎么办? 我们不想让 buffer pool manager 随机地把 hash table page 交换到内存中，因为对 hash table 的操作是频繁的，这会带来很大开销。

这需要我们对 build 和 probe 两个阶段做一些改动。

Phase #1: Build

- 使用 join attribute 把两个表都散列到不同 partition 上。 

Phase #2: Probe

- 比较两个表的对应 partition 的元组进行匹配。

![](https://github.com/SUNLIFAN/images/blob/main/post/db1104.png?raw=true)

如果 bucket 在内存放不下，那么可以进行递归的切分，把表分成能放入内存的 chunks.

- 为 $bucket_{R,i}$ 建立第二个哈希表，使用 $h_2$
- 在 probe 的时候对 $bucket_{S,i}$ 也使用 $h_2$ 之后再匹配。

![](https://github.com/SUNLIFAN/images/blob/main/post/db1105.png?raw=true)

$BuildCost = 2(M+N)$，分别是对两个 table 的读出和写入。

$ProbeCost = M + N$，分别是对两个 table 的读。

因此，$Cost = 3(M + N)$

## Conclusion

![](https://github.com/SUNLIFAN/images/blob/main/post/db1106.png?raw=true)

在大多数情况下 hash join 都比 sort join 要好，但是在不平衡的数据和需要输出排序结果的情况下，sort join 更优，优秀的 DBMS 两者都会使用。