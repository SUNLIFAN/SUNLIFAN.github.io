---
title: 'OSTEP Notes: Memory Virtualization'
date: 2022-11-17
permalink: /posts/2022/11/ostep03
tags:
  - computer science
  - operating system
---

> Like CPU resources, operating systems provide certain illusions to programs in terms of memory. For example, providing each process the illusion that it has a large personal address space.

## Address Space

### Early System

早期的计算机系统上只有一个运行的进程，这个进程占有所有的内存资源。

### Multi-programming and Time sharing

多道程序设计对内存管理提出了更高的要求，一个简单的方法是每次只让一个进程进入内存，切换时调出，重新调入另一个进程，但是这样的效率是不可接受的，更好的方法是让多个进程同时驻留在主存中，这需要保持进程和进程之间，操作系统和进程之间的 **隔离性**。

### The Address Space

![](https://github.com/tiebreaker4869/images/blob/main/post/ostep021.png?raw=true)

> Address Space Example

**地址空间**是内存最基础的抽象，是进程看待内存的视角，包含: 代码、堆栈。

每个进程都认为自己被加载到一片从 0 开始的连续的地址空间，这实际上当然是不可能的，这是由 OS 提供了虚拟化的内存，OS 通过 **地址转换** 来把用户编程时使用的虚拟地址空间中的 **逻辑地址** 映射到 **物理地址**。

### Goals

内存虚拟化的设计目标:

- Transparency: 进程应该感知不到 OS 做了内存虚拟化

- Efficiency: 内存虚拟化不应带来过大的额外开销

- Protection: 进程之间，OS 和进程之间应该保持良好的隔离性

## Mechanism: Address Translation

为了构建有效率的虚拟内存机制，我们需要使用基于硬件 (仍然需要 OS 辅助) 的地址转换机制。

下面关于地址转换机制的讨论首先都假设内存空间足够，再之后我们会去除这个假设。。

### Dynamic (Hardware-based)Relocation

使用一个 base-bound 寄存器对，base 存储当前进程使用的地址空间的基地址，bound 表示当前进程使用的地址空间的限长。

### Hardware Support: A Summary

- CPU 提供两种特权级，防止用户执行越权的指令

- Base-Bound Registers: 帮助完成地址转换

- 异常处理机制，在进程访问不和法的地址空间时剥夺进程的 CPU 控制权

### OS Issue

- Memory Management: 分配和去配内存，通常通过一个 free list 来完成

- Base-Bound Registers Management: 在上下文切换的时候保存和加载寄存器对

- Exception Handling: 提供异常处理程序，通常是终止进程

## Segmentation

基本思想:

- 每个程序由若干个段组成，每个段从零开始编址，是一片连续的地址空间。

- 段式存储管理的逻辑地址由两部分组成: 段选择符: 段内偏移

![](https://github.com/tiebreaker4869/images/blob/main/post/ostep026.png?raw=true)

段式存储管理的地址转换流程

## Free Space Management

一般使用链表 (free list) 来管理空闲的主存空间，每次需要获取一块内存空间时就从 free list 中获取。

常见的主存分配算法有如下几种:

- First Fit: 直接使用 free list 上第一个找到的能够容纳的内存块。

- Next Fit: 从上次扫描结束的地方开始线性扫描，直到找到第一个适配的内存块。

- Best Fit: 使用大于申请内存的最小的空闲内存块

- Worst Fit: 使用最大的内存块

上面几种方法都无法避免产生外部碎片。

- Buddy Allocation: Buddy 分配算法是一种方便空闲内存合并的算法。它把初始时的空闲内存看做一块大小为 $2^N$ 的内存块，当要分配内存的时候，不断递归地分割剩余空间，直到找到能容纳申请空间的最小的内存块。在下图的例子中，就是最左边的 8 KB 的内存块。算法的精妙之处在于内存去配的时候，当归还这个 8 KB 的内存块之后，OS 会检查它的 Buddy Block 是否空闲，然后进行递归地合并。

![](https://github.com/tiebreaker4869/images/blob/main/post/ostep022.png?raw=true)

> Buddy Allocator Example: request a 7 KB block

Buddy Allocatin 由于分配的都是特定长度的内存块，因此会有内部碎片的问题。

## Paging

分段的方法把内存分为可变大小的段，而分页把物理内存分为固定大小的页框，管理的内存块是特定大小的，称为页。固定大小带来的一个好处是简洁性，当获取空闲内存空间的时候，直接按需获取即可，比如需要 4 个页，那么直接从 free list 中取出前 4 项即可。为了完成地址转换，OS 只需要为每个进程维护一个页表，记录地址转换关系，逻辑地址被分为虚页号和页内偏移两个部分，虚页号作为页表中页表项的索引查询物理页框号，与业内偏移拼起来构成物理地址。

### Where are page table stored?

由于要给每个进程都维护一个有一定大小的页表，Cache 等高速缓存存储器无法容纳，因此需要存放到内存里。

### What is stored in the page table?

以线性页表为例，每个页表项包含如下信息:

- Physical Page Number

- Valid Bit: Is this page being used?

- Present Bit: is this page in the memory?

- Protection Bit: Read / Write Permission

- Dirty Bit: has it been modified since being brought into memory?

- Reference Bit: has the page been accessed? Useful for telling what’s popular to be kept in memory.


### Paging: too slow

由于页表也保存在内存中，因此我们需要访问两次主存才得到我们想要访问的内存位置，这还仅仅是对于单级页表

## Paging: Faster Translation

由于页表带来的多次访问主存的开销是不可接受的，因此我们引入了 TLB，作为页表的缓存，加速了地址转换的过程。

### TLB Algorithm

```
VPN = (VirtualAddress & VPN_MASK) >> SHIFT
(Success, TlbEntry) = TLB_Lookup(VPN)
if (Success == True) // TLB Hit
if (CanAccess(TlbEntry.ProtectBits) == True)
    Offset = VirtualAddress & OFFSET_MASK
    PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
    Register = AccessMemory(PhysAddr)
else
    RaiseException(PROTECTION_FAULT)
else // TLB Miss
    RaiseException(TLB_MISS)
```

### Handling TLB Miss

TLB miss 可以由软件或者硬件来处理，早期的系统往往通过硬件来处理，现代的系统往往只抛出异常，然后把控制权转交给 trap handler 来处理，这种方式的有点是灵活性。

### TLB Content

TLB 表项存储 VPN 到 FPN 的映射关系，还存储了其他属性位，比如有效位保护位等。

### Context Switches

一个问题是 TLB 中存储的映射只对当前的进程有效，那么当发生上下文切换之后该怎么办? 一个做法是直接 flush 掉所有表项，但是这种做法的开销太大，另一种做法是在表项中标识属于哪个进程。

### Replacement Policy

当 TLB 满了，如果有新的表项需要进入，需要替换掉其中的表项，这里我们使用 LRU 算法。

## Paging: Smaller Page Table

原始的单级页表有一个问题是它占用了太多的内存空间。对于一个 32 位的系统，所有进程的页表需要消耗几百 MB，这对系统来说是一个很大的内存开销。一个解决办法是增大页的大小，这样就会减少页表项的数量，但是这又带来了更多的内部碎片。段页式也是一个可行的办法，但是这种方式仍然容易带来很多碎片问题。

### Multi-Level Page Table

线性页表带来的浪费来源于它不得不保留那些无效的页对应的页表项的空间，多级页表解决了这个问题。多级页表把线性页表组织成类似于树的结构，在内部节点只存指向下一级页表的索引，在最后一级页表的页表项才存储物理页号。如果某一级页目录的某个表项对应的下一级页表中没有有效的页表项，那么将不会为它的下一级页表分配空间，这就是多级页表节约空间的来源。这种做法的缺点是牺牲了时间效率，需要更多次访问主存或者 TLB。

![](https://github.com/tiebreaker4869/images/blob/main/post/ostep023.png?raw=true)

### Inverted Page Table

基本设计思想:

- 针对内存中的每个物理页框建立一个页表项，按照块号排序

- 表项包含: 正在访问该页框的进程标识，页号及特征位，和哈希链指针等

- 用来完成物理地址到逻辑地址的转换

![](https://github.com/tiebreaker4869/images/blob/main/post/ostep024.png?raw=true)

使用倒置页表完成地址转换的过程就是在倒置页表中搜索的过程。

基于倒置页表的地址转换过程:

- MMU 通过哈希表把进程标识和虚页号转换成一个哈希值，指向 IPT 的某个表项

- 通过遍历哈希链找到对应的物理页框，索引就是物理页框号，拼接上页内偏移量就是物理地址

- 若遍历整个倒置页表仍然找不到，则抛出缺页异常，请求 OS 把页调入

## Beyond Physical Memory: Mechanisms

![](https://github.com/tiebreaker4869/images/blob/main/post/ostep025.png?raw=true)

这就是虚拟存储器的思想:

- 虚拟地址空间 (辅存): 容纳程序装入

- 物理地址空间 (主存)：容纳程序执行

这为用户提供了更大的地址空间，对多道程序设计是很重要的。

### Swap Space

swap space 是在磁盘中分配的一块空间，用来存储目前没有正在被使用的页，当需要这些页中，可以将他们从磁盘中加载出去。为了实现这个操作，需要记录页的磁盘地址。

### Present Bit

页表项中的 present bit 指示了这个页是否在主存中，如果在主存中则可以获取物理地址之后从主存中读取，如果不在则需要抛出 page fault.

![](https://github.com/tiebreaker4869/images/blob/main/post/ostep027.png?raw=true)

### The Page Fault

当页不在主存中，会抛出一个 page fault，控制权转交给 page fault handler，根据页表项中的磁盘地址找到页在磁盘中的位置，并从磁盘调入内存。如果内存已满，那么会根据特定的替换策略调出一个页。

## Beyond Physical Memory: Policies

当主存空间已满的时候又需要装入新页的时候，就需要按照一定的算法把主存中的某些页驱逐出去。选择淘汰页的过程叫做页面调度，选择淘汰页面的算法叫做页面替换算法。

页面替换算法的设计对系统的效率是影响很大的，差劲的页面替换算法会带来抖动现象，即刚被调出内存的页又被调回来。这种情况下缺页率提高，多次的缺页异常处理带来了很大开销。

### Affecting Factors

影响缺页率的因素有如下:

- 分配给进程的页框数：分配的页框数越多缺页率越低

- 页面的大小: 页面越大缺页率越低

- 用户编写的程序的局部性: 局部性越好缺页率越低

- OPT 页面调度算法: 是理想的调度算法，它的基本思想是，当要调入新页面的时候，首先调出那些以后不会使用的页面，如果没有这样的页面，那么调出下一次使用时间离现在最久的页面。OPT 算法需要知道未来的信息，只能模拟，不能实现。

- FIFO：根据页面进入内存的时间调出页面。每次要调出页面的时候，选择最早进入内存的页调出。模拟的是程序的顺序执行，有一定的合理性。

- LRU：淘汰最近一段时间内较久未使用的页，即那些刚刚被使用的页面最近还可能被使用。模拟了程序的局部特性，但是严格实现的开销太大。

- LFU: 淘汰最近一段时间内访问次数较少的页。设置一个时间间隔，在这个时间间隔内，每次被访问则计数器 + 1，间隔结束则计数器清零。

- CLOCK：使用一个循环队列和一个队列指针，循环队列就像一个表盘，队列指针项表盘的指针。页面调入主存时，标志位置为 1，访问主存页面的时候，其标志位置为 1，当淘汰页面的时候，从当前指针指向的页面开始扫描，扫描到标志位为 1 的则置为 0，并前进一步，扫描到 0 的则淘汰该页面。

