---
title: 'Intro to Database System : Sorting & Aggregation'
date: 2022-12-12
permalink: /posts/2022/12/15445-10
tags:
  - computer science
  - database
---
## Content

1. Sorting

2. Aggregation

## Sorting

### Why do we need to sort?

由于关系模型/SQL 本身是无序的，但是在一些场合我们需要排序 (ORDER BY 子句)，或者排序之后更方便 (DISTINCT，GROUP BY 子句，对排序好的元组自底向上建立 B+ 树速度更快)

### In-Memory Sorting

如果内存能够容得下数据，那么可以直接使用常规的排序方法，比如快排，但是这样的假设使得数据库不 scalable. 当数据大小超过内存的容量时，我们设计排序算法的时候需要考虑到磁盘 I/O 的代价。

### TopN Heap Sort

如果一个查询带有 ORDER BY 和 LIMIT 子句，那么我们只需要扫描一轮数据并找出 TOP-N. 理想的情况是内存可以容得下数据集，那么我们只需要维护一个在内存中的优先队列即可。

### External Merge Sort

external merge sort 是一种分治算法，它先把无法放入主存的数据切分成若干个 chunks，每个 chunk 都可以放进主存，每个 chunk 称为一个 run，通常是整数个 page 大小，先对每个 run 进行排序，然后把若干个 run 进行归并，这个过程和常规的 merge sort 是类似的。

Phase #1: Sorting
- 把能放进内存的 chunk 内部先排好序，然后写回到磁盘。

Phase #2: Merge
- 把排序好的 chunk 组成更大的排序好的文件。

### Sorted Run

一个 run 是一个 KV pair 的列表，其中，key 是用来排序的属性，value 有两种选择，如果采用 early materialization 的策略，那么 value 是整个 tuple，如果采用 late materialization 的策略，那么 value 是 record id.

### 2-way external merge sort example

![](https://github.com/SUNLIFAN/images/blob/main/post/db1001.png?raw=true)

2-way merge sort 只需要 3 个 buffer，两个分别给两个 way，一个给输出。但是如果我们有更多的 buffer，如果 disk IO 是阻塞式的话，也无法利用这些多余的 buffer。

### Double buffering optimization

prefetch the next run in background while processing current run. 这种方式减少了等待 IO 的时间。

### General External Merge Sort

![](https://github.com/SUNLIFAN/images/blob/main/post/db1002.png?raw=true)

### Comparison Optimization

- Code specialization: 对于某些键类型，可以采用硬编码 cmp 函数的方式，而不是需要传递 cmp 函数的指针。 

- Suffix truncation: 对于 varchar 类型，先比较二进制形式的前缀，而不是逐个字符比较，如果前缀相同再采用逐个字符比较。


### Using B+ Tree for sorting

如果需要被排序的属性上已经有了一个 B+ 树索引，那么只需要遍历 B+ 树的 leaf pages 就可以了。但是这也分为两种情况，并非每种情况都是好的。

- Clustered Index: 如果是聚簇索引，那么元组在磁盘是按照索引的顺序在磁盘顺序排列，在这种情况下，通过遍历 leaf pages 的方式是好于 external merge sort 的，因为不需要计算开销，而且磁盘 IO 都是 sequential 的。

- Unclustered Index: 如果是非聚簇索引，那么在 leaf pages 上都是 record id，需要再通过 record id 来获取 tuple，这可能会带来很多 random IO，通常是不好的。

## Aggregation

aggregation 的目的是把某一个属性的一系列 value，规约为一个标量值。DBMS 需要一个方法来找到那些在某个属性上有相同的 distinguishing attribute 的元组，来完成 groping 的操作。

有两种实现方式:

- Sorting

- Hashing

### Sorting Aggregation

首先对 GROUP BY 键上的元组进行排序。 如果内存足够，则放入缓冲池,使用内存排序算法（例如，快速排序）

如果数据大小超过内存，使用 external merge sort。

然后，DBMS 对已排序的数据执行顺序扫描以计算聚合，operator的输出将按key排序。

![](https://github.com/SUNLIFAN/images/blob/main/post/db1003.png?raw=true)

然而，如果我们并不需要数据排好序呢（GROUP BY，DISTINCT），那么通过排序来聚合就显得有点大材小用了。一种备选的方法是通过 hashing 来聚合。这种方法在计算开销上比排序要小。

### Hashing Aggregation

hashing aggregation 的方法在扫描 record 的时候实时维护一个 hash table，对于每条 record，首先检查是否已有对应的 entry，如果还没有，那么把这个 record 填入 hash table 的对应位置，如果已经有，那么根据聚合的目的对已有的 entry 进行修改。

如果内存能够容得下这个 hash table，这种情况是 trivial 的，如果内存无法容下 hash table，那么需要溢出到磁盘中。

Phase #1: Partition
- 使用哈希函数 $h_1$ 将所有元组散列到基于目标键的磁盘上的分区（partition），这会将匹配的元组放在同一个分区，DBMS 通过输出缓冲区将分区溢出到磁盘上。（这一步我的理解是把原来很大的数据集拆成若干内存可以容得下的分区，然后进行分治处理，由于聚合是把若干元组压缩称一个标量值，计算聚合值需要的哈希表应该能放到内存中）

Phase #2: Rehash
- 对于磁盘上的每个分区，将其读入内存，并基于第二个哈希函数 $h_2$，构建内存中的哈希表，将匹配的元组汇集到一起计算聚合值，具体来说，在 Rehash 阶段，DBMS 可以存储 (GroupByKey -> RunningValue) 来计算聚合。 RunningValue 取决于具体的聚合函数，每次碰到一个新元组时:
  - 如果 hash table 中还没有对应的 GroupByKey，那么插入新的 (GroupByKey -> RunningValue).
  - 如果 hash table 中已经有对应的 GroupByKey，那么只需要更新对应的 RunningValue. 

![](https://github.com/SUNLIFAN/images/blob/main/post/db1004.png?raw=true)